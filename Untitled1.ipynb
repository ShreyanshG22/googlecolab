{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "D5IHoMy6mduH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8a7d1c08-9c86-496c-862c-2a8f569a59d3"
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# define documents\n",
        "docs = [\"beyonc giselle knowles was born in houston texas\",\n",
        "\t\t\"beyonc attended st. mary elementary school in fredericksburg\"]\n",
        "# define class labels\n",
        "labels = array([[0,0,0,1,1,0,0,0],[0,1,1,1,0,0,0,0]])\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(docs)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(docs)\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 8\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "[[1, 2], [1, 3]]\n",
            "[[1 2]\n",
            " [1 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DroLWAmmxIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6d6507d-3665-4183-a099-3e3d36d4844b"
      },
      "cell_type": "code",
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "file = '/content/gdrive/My Drive/BTech Project/glove.42B.300d.txt'\n",
        "f = open(file)\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 1917494 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fr5mLT8QSid2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88cP8raGSO69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "bad8d342-b113-4df8-b9ac-dd3c6424c0af"
      },
      "cell_type": "code",
      "source": [
        "print(embedding_matrix)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.28489     0.60303003 -0.52146    ...  0.50771999  0.55796999\n",
            "   0.097686  ]\n",
            " [ 0.45537999 -0.21951    -0.61341    ... -0.12565     0.39353999\n",
            "   0.04288   ]\n",
            " [ 0.13523     0.20027     0.23433    ...  0.47446999 -0.04458\n",
            "   0.098734  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jPWyIMM-m1BO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "83eb1f9a-dce3-490f-ac54-c0a96193cdcd"
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=8, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 8, 300)            4500      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 19208     \n",
            "=================================================================\n",
            "Total params: 23,708\n",
            "Trainable params: 19,208\n",
            "Non-trainable params: 4,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "<keras.callbacks.ModelCheckpoint object at 0x7f9bb9d273c8>\n",
            "Accuracy: 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vkK30WsGO4dJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a10c56bb-beeb-4237-c7f8-a6ba5d425f57"
      },
      "cell_type": "code",
      "source": [
        "texts =\"beyonc was in born\"\n",
        "t.fit_on_texts(texts)\n",
        "index_list = t.texts_to_sequences(texts)\n",
        "x_train = pad_sequences(index_list, maxlen=max_length, padding='post')\n",
        "preds = model.predict_classes(x_train)\n",
        "print(preds)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 6 6 3 3 3 3 5 3 1 3 6 3 3 5 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}