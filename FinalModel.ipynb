{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyanshG22/googlecolab/blob/master/FinalModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "D5IHoMy6mduH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2ERDFDON_Nt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define documents\n",
        "inputFile = '/content/gdrive/My Drive/BTech Project/training.txt'\n",
        "outputLabel = '/content/gdrive/My Drive/BTech Project/l_training.txt'\n",
        "inputValidationFile = '/content/gdrive/My Drive/BTech Project/validation.txt'\n",
        "outputValidationLabel = '/content/gdrive/My Drive/BTech Project/l_validation.txt'\n",
        "testFile = '/content/gdrive/My Drive/BTech Project/testing.txt'\n",
        "testLabel = '/content/gdrive/My Drive/BTech Project/l_testing.txt'\n",
        "file = '/content/gdrive/My Drive/BTech Project/glove.42B.300d.txt'\n",
        "Glovedict = '/content/gdrive/My Drive/BTech Project/glovedict.txt'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-wYzzsJCi4V",
        "colab_type": "code",
        "outputId": "a3c5f558-464e-4228-a75f-82c1f86a1539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''#### Kaam Ka Nahi Hai ####\n",
        "\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(docs)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(docs)\n",
        "# pad documents to a max length of 780 words\n",
        "max_length = 780\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(len(padded_docs[0]))'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#### Kaam Ka Nahi Hai ####\\n\\n# prepare tokenizer\\nt = Tokenizer()\\nt.fit_on_texts(docs)\\nvocab_size = len(t.word_index) + 1\\n# integer encode the documents\\nencoded_docs = t.texts_to_sequences(docs)\\n# pad documents to a max length of 780 words\\nmax_length = 780\\npadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\\nprint(len(padded_docs[0]))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9DroLWAmmxIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''def loadGloveModel(gloveFile):\n",
        "    print (\"Loading Glove Model\")     \n",
        "    with open(gloveFile, encoding=\"utf8\" ) as f:\n",
        "       content = f.readlines()\n",
        "    model = {}\n",
        "    for line in content:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
        "        model[word] = embedding\n",
        "    print (\"Done.\",len(model),\" words loaded!\")\n",
        "    return model\n",
        "     \n",
        "embeddings_index = loadGloveModel(file)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7rCaNQNEok9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "f = open(inputFile, encoding=\"utf8\" )\n",
        "d = f.readlines()\n",
        "demon = []\n",
        "for j in d:\n",
        "  i = j.strip()\n",
        "  lambai = len(i.split())\n",
        "  if lambai != 780:\n",
        "    i = i + \" #\"*(780-lambai)\n",
        "  demon.append(i)\n",
        "f.close()\n",
        "docs = demon\n",
        "\"\"\"\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "with open(Glovedict, \"r\") as gr:\n",
        "  embeddings_index = json.load(gr)\n",
        "\"\"\"\n",
        "embedding_matrix = []\n",
        "count = 0\n",
        "for line in docs:\n",
        "  count += 1\n",
        "  line = line.strip().split()\n",
        "  embed = []\n",
        "  for word in line:\n",
        "    embedding_vector = np.array(embeddings_index.get(word, embeddings_index.get(\"#\")))\n",
        "    embed.append(list(embedding_vector))\n",
        "  embedding_matrix.append(embed)\n",
        "  if count > 511:\n",
        "    break\n",
        "InputLines = np.array(embedding_matrix)\n",
        "print(InputLines.shape)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z772c3WeV2xc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define class labels\n",
        "\"\"\"\n",
        "with open(outputLabel, encoding=\"utf8\" ) as f:\n",
        "  label = json.load(f)\n",
        "lab = label[\"label\"]\n",
        "lab = lab[:512]\n",
        "labels = np.array(lab)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-iIIBuHHJWPh",
        "colab_type": "code",
        "outputId": "5b947bd6-edb6-463f-e625-91f704f3d14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''#Loading only required wordvectors\n",
        "f = open(inputFile, encoding=\"utf8\")\n",
        "gd = open(Glovedict, \"w\")\n",
        "demon = {}\n",
        "for line in f:\n",
        "    line = line.strip()\n",
        "    lambai = len(line.split())\n",
        "    if lambai != 780:\n",
        "      line = line + \" #\"*(780-lambai)\n",
        "    line = line.split()\n",
        "    embed = []\n",
        "    for word in line:\n",
        "      demon[word] = list(embeddings_index.get(word, embeddings_index.get(\"#\")))\n",
        "gd.write(json.dumps(demon))'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254332546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "WBRDXiOG0RkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_generator(batch_size):\n",
        "    input_f = open(inputFile, encoding=\"utf8\" )\n",
        "    output_f = open(outputLabel, encoding=\"utf8\" )\n",
        "    # Initialize a counter\n",
        "    counter = 0\n",
        "    while True:\n",
        "        counter+=1\n",
        "        input_l = []\n",
        "        output_l = []\n",
        "        li = 0\n",
        "        x,y=input_f.readline(),output_f.readline()\n",
        "        while x and li < batch_size:\n",
        "            input_l.append(x)\n",
        "            output_l.append(y)\n",
        "            x,y=input_f.readline(),output_f.readline()\n",
        "            li += 1\n",
        "        if li < batch_size:\n",
        "            input_f.seek(0)\n",
        "            output_f.seek(0)\n",
        "            input_l += [next(input_f) for x in range(batch_size-li)]\n",
        "            output_l += [next(output_f) for x in range(batch_size-li)]\n",
        "        embedding_matrix = []\n",
        "        for j in input_l:\n",
        "            i = j.strip()\n",
        "            lambai = len(i.split())\n",
        "            if lambai != 780:\n",
        "                i += \" #\"*(780-lambai)\n",
        "            line = i.strip().split()\n",
        "            embed = []\n",
        "            for word in line:\n",
        "                embedding_vector = np.array(embeddings_index.get(word, embeddings_index.get(\"#\")))\n",
        "                embed.append(list(embedding_vector))\n",
        "            embedding_matrix.append(embed)\n",
        "        InputLines = np.array(embedding_matrix)\n",
        "        f_label = []\n",
        "        for label in output_l:\n",
        "          label = label.strip().split()\n",
        "          label = [int(i) for i in label]\n",
        "          lambai2 = len(label)\n",
        "          if lambai2 != 780:\n",
        "            label += [0]*(780-lambai2)\n",
        "          f_label.append(label)\n",
        "        labels = np.array(f_label)\n",
        "        #if counter ==1:\n",
        "        #    print(labels.shape)\n",
        "        yield InputLines, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OeTR7nrSpgdO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate_generator(batch_size):\n",
        "    input_f = open(inputValidationFile, encoding=\"utf8\" )\n",
        "    output_f = open(outputValidationLabel, encoding=\"utf8\" )\n",
        "    # Initialize a counter\n",
        "    counter = 0\n",
        "    while True:\n",
        "        counter+=1\n",
        "        input_l = []\n",
        "        output_l = []\n",
        "        li = 0\n",
        "        x,y=input_f.readline(),output_f.readline()\n",
        "        while x and li < batch_size:\n",
        "            input_l.append(x)\n",
        "            output_l.append(y)\n",
        "            x,y=input_f.readline(),output_f.readline()\n",
        "            li += 1\n",
        "        if li < batch_size:\n",
        "            input_f.seek(0)\n",
        "            output_f.seek(0)\n",
        "            input_l += [next(input_f) for x in range(batch_size-li)]\n",
        "            output_l += [next(output_f) for x in range(batch_size-li)]\n",
        "        embedding_matrix = []\n",
        "        for j in input_l:\n",
        "            i = j.strip()\n",
        "            lambai = len(i.split())\n",
        "            if lambai != 780:\n",
        "                i += \" #\"*(780-lambai)\n",
        "            line = i.strip().split()\n",
        "            embed = []\n",
        "            for word in line:\n",
        "                embedding_vector = np.array(embeddings_index.get(word, embeddings_index.get(\"#\")))\n",
        "                embed.append(list(embedding_vector))\n",
        "            embedding_matrix.append(embed)\n",
        "        InputLines = np.array(embedding_matrix)\n",
        "        f_label = []\n",
        "        for label in output_l:\n",
        "          label = label.strip().split()\n",
        "          label = [int(i) for i in label]\n",
        "          lambai2 = len(label)\n",
        "          if lambai2 != 780:\n",
        "            label += [0]*(780-lambai2)\n",
        "          f_label.append(label)\n",
        "        labels = np.array(f_label)\n",
        "        #if counter ==1:\n",
        "        #    print(labels.shape)\n",
        "        yield InputLines, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdORJS8rrCIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_data():\n",
        "    input_f = open(testFile, encoding=\"utf8\" )\n",
        "    output_f = open(testLabel, encoding=\"utf8\" )\n",
        "    input_l = input_f.readlines()\n",
        "    output_l = output_f.readlines()\n",
        "    embedding_matrix = []\n",
        "    for j in input_l:\n",
        "        i = j.strip()\n",
        "        lambai = len(i.split())\n",
        "        if lambai != 780:\n",
        "            i += \" #\"*(780-lambai)\n",
        "        line = i.strip().split()\n",
        "        embed = []\n",
        "        for word in line:\n",
        "            embedding_vector = np.array(embeddings_index.get(word, embeddings_index.get(\"#\")))\n",
        "            embed.append(list(embedding_vector))\n",
        "        embedding_matrix.append(embed)\n",
        "    InputLines = np.array(embedding_matrix)\n",
        "    f_label = []\n",
        "    for label in output_l:\n",
        "      label = label.strip().split()\n",
        "      label = [int(i) for i in label]\n",
        "      lambai2 = len(label)\n",
        "      if lambai2 != 780:\n",
        "        label += [0]*(780-lambai2)\n",
        "      f_label.append(label)\n",
        "    labels = np.array(f_label)\n",
        "    return InputLines, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jPWyIMM-m1BO",
        "colab_type": "code",
        "outputId": "f6334bf6-944c-4e0f-a4ea-fefc0b812ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "cell_type": "code",
      "source": [
        "def define_model():\n",
        "      # define model\n",
        "      model = Sequential()\n",
        "      model.add(LSTM(780, batch_input_shape=(None, 780, 300), return_sequences=False))\n",
        "      model.add(Dense(780))\n",
        "      model.add(Dense(780, activation='sigmoid'))\n",
        "      return model\n",
        "\n",
        "model = define_model()\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "print(\"Idhar Tak To Aaya!\")\n",
        "checkpoint = ModelCheckpoint('/content/gdrive/My Drive/BTech Project/model_best_weights.h5', monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
        "# fit the model\n",
        "training_generator = data_generator(batch_size=64)\n",
        "validation_generator = validate_generator(batch_size=64)\n",
        "history = model.fit_generator(training_generator,validation_data=validation_generator, epochs=30, callbacks=[checkpoint], verbose=1,steps_per_epoch=9736//64,validation_steps=4868//64)\n",
        "#history = model.fit(trainX, trainY,validation_split = 0.4, epochs=30, batch_size=64, callbacks=[checkpoint], verbose=1)\n",
        "\n",
        "# evaluate the model\n",
        "testX, testY = test_data()\n",
        "loss, accuracy = model.evaluate(testX, testY, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6c8eb4b684b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-6c8eb4b684b5>\u001b[0m in \u001b[0;36mdefine_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m       \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m780\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m780\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m780\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MZa_hx2fHavf",
        "colab_type": "code",
        "outputId": "6f1dbe9e-e6ab-4b92-d7c3-5260874d3dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZS0AUdm69XnT",
        "colab_type": "code",
        "outputId": "e7952569-d31a-4e3a-9476-c5a041681bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13685
        }
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(testX)\n",
        "print(testX[0])\n",
        "for i in preds[0]:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.036429  -0.28592    0.063387  ... -0.48926    0.30537    0.27273  ]\n",
            " [-0.20838   -0.14932   -0.017528  ... -0.54066    0.21199   -0.0094357]\n",
            " [-0.11092    0.034125  -0.098563  ...  0.49271   -0.27157   -0.22677  ]\n",
            " ...\n",
            " [-0.085367  -0.38418    0.42207   ...  0.36012   -0.0089095 -0.40729  ]\n",
            " [-0.085367  -0.38418    0.42207   ...  0.36012   -0.0089095 -0.40729  ]\n",
            " [-0.085367  -0.38418    0.42207   ...  0.36012   -0.0089095 -0.40729  ]]\n",
            "0.23079193\n",
            "0.13190144\n",
            "0.11187887\n",
            "0.016699612\n",
            "0.00084272027\n",
            "0.044671178\n",
            "0.1092397\n",
            "0.044615835\n",
            "0.075202614\n",
            "0.021031648\n",
            "0.027977407\n",
            "0.04207748\n",
            "0.037034005\n",
            "0.1440849\n",
            "0.09239811\n",
            "0.040826112\n",
            "0.02934885\n",
            "0.040021867\n",
            "0.02169162\n",
            "0.04760304\n",
            "0.03304985\n",
            "0.033725947\n",
            "0.06830776\n",
            "0.004845947\n",
            "6.902218e-05\n",
            "0.014947057\n",
            "0.0019657016\n",
            "0.015426755\n",
            "0.011986941\n",
            "0.02661398\n",
            "0.026315212\n",
            "0.05496764\n",
            "0.04870206\n",
            "0.07913804\n",
            "0.20760113\n",
            "0.21404916\n",
            "0.027038336\n",
            "0.0341565\n",
            "0.0015960038\n",
            "0.0\n",
            "0.03528574\n",
            "0.029011369\n",
            "0.019720644\n",
            "0.01649189\n",
            "0.017130673\n",
            "0.015316665\n",
            "0.0\n",
            "0.03438598\n",
            "0.01584658\n",
            "0.009461492\n",
            "0.0\n",
            "2.9802322e-08\n",
            "0.0009677708\n",
            "0.0\n",
            "0.0\n",
            "0.022110432\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "2.9802322e-08\n",
            "0.030986547\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.00021764636\n",
            "6.2584877e-07\n",
            "0.0002978444\n",
            "0.00038915873\n",
            "0.00038707256\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0027660728\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}